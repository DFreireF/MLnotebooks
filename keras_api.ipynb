{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfjiNhDED3aU"
      },
      "source": [
        "# Model building with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHmaA1MBEOTD"
      },
      "source": [
        "In this notebook, you will get to know keras' **functional API** by creating a simple model, and by implementing and adding your own layer.\n",
        "\n",
        "We are not going to train it, but the purpose of this exercise is to be able to use keras for building flexible models.\n",
        "\n",
        "**This exercise is organized in 3 steps**\n",
        "\n",
        "1. Build a simple, fully-connected network for a classification task with the functional API\n",
        "2. Create your own layer which is meant to perform input feature scaling.\n",
        "3. Add the layer to your model.\n",
        "4. Extend your network to model a multi-purpose network doing also a regression on some quantity."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Simple model"
      ],
      "metadata": {
        "id": "iX12CeGZrGJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsGU1wcJFL3O"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build a model with to following specs\n",
        "\n",
        "- 32 input features\n",
        "- 5 hidden layers with 128 units each\n",
        "- \"elu\" activation function\n",
        "- a final \"softmax\" layer with 3 units (3-class classification)"
      ],
      "metadata": {
        "id": "yDRj39gnrVDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Input(shape=(32,))\n",
        "\n",
        "# stack hidden layers\n",
        "a = x\n",
        "for _ in range(5):\n",
        "    # dense layer\n",
        "    a = tf.keras.layers.Dense(128)(a)\n",
        "\n",
        "    # activation\n",
        "    a = tf.keras.layers.Activation(\"elu\")(a)\n",
        "\n",
        "# output layer\n",
        "y = tf.keras.layers.Dense(3, activation=\"softmax\")(a)\n",
        "\n",
        "# construct the model\n",
        "model = tf.keras.Model(inputs=x, outputs=y)"
      ],
      "metadata": {
        "id": "DcJCN5xzrN76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can check if your model produces some outputs.\n",
        "\n",
        "**Remember**, the weights are already initialized (can you find out how?) but they were not optimized yet by means of a training process. However, even with the initial weights, you should be able to perform a prediction."
      ],
      "metadata": {
        "id": "BFfZCzWEtCGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creata a batch of 10 input samples\n",
        "random_inputs = np.random.random((10, 32))\n",
        "pred = model.predict(random_inputs)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GgoPRDhuVcK",
        "outputId": "5828e6b2-c3a4-4f8f-daaf-2adf5a96f965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 765ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19352934, 0.43056267, 0.375908  ],\n",
              "       [0.31703332, 0.33084533, 0.35212138],\n",
              "       [0.32126305, 0.34349218, 0.3352447 ],\n",
              "       [0.25064832, 0.405579  , 0.34377265],\n",
              "       [0.23130643, 0.39652428, 0.37216923],\n",
              "       [0.20979956, 0.45050025, 0.33970016],\n",
              "       [0.2732788 , 0.39144984, 0.33527136],\n",
              "       [0.24330816, 0.39655355, 0.36013833],\n",
              "       [0.29108942, 0.39195138, 0.3169592 ],\n",
              "       [0.35611117, 0.31104642, 0.33284244]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you understand the shape of the output?\n",
        "\n",
        "Verify that the softmax activation in the last layer worked, i.e., check that the sum of outputs adds up to 1."
      ],
      "metadata": {
        "id": "hnA6RM9purHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Custom layer\n",
        "\n",
        "Now we are going to write our own custom layer that is supposed to apply input feature scaling. For this, we subclass the `tf.keras.layers.Layer` base class and implement the minimal set of methods to integrate it into our model.\n",
        "\n"
      ],
      "metadata": {
        "id": "1sV6dep_vFma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the feature scaling procedure as a custom keras layer\n",
        "# that has, of course, no weights as it is not trainable\n",
        "# see https://keras.io/guides/making_new_layers_and_models_via_subclassing for more info\n",
        "\n",
        "class FeatureScaling(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, means, stddevs):\n",
        "        \"\"\"\n",
        "        Constructor. Stores arguments as instance members.\n",
        "        \"\"\"\n",
        "        super(FeatureScaling, self).__init__(trainable=False)\n",
        "\n",
        "        self.means = means\n",
        "        self.stddevs = stddevs\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Method that is required for model cloning and saving. It should return a\n",
        "        mapping of instance member names to the actual members.\n",
        "        \"\"\"\n",
        "        return {\"means\": self.means, \"stddevs\": self.stddevs}\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "        Method that, given an input shape, defines the shape of the output tensor.\n",
        "        This way, the entire model can be built without actually calling it.\n",
        "        \"\"\"\n",
        "        return (input_shape[0], input_shape[1])\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Any variables defined by this layer should be created inside this method.\n",
        "        This helps Keras to defer variable registration to the point where it is\n",
        "        needed the first time, and in particular not at definition time.\n",
        "        \"\"\"\n",
        "        # nothing to do here as our feature scaling has not trainable parameters\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"\n",
        "        Payload of the layer that takes inputs and computes the requested output\n",
        "        whose shape should match what is defined in compute_output_shape.\n",
        "        \"\"\"\n",
        "        # scale each feature such that it is distributed around 0 with a standard deviation of 1\n",
        "        return (x - self.means) / self.stddevs"
      ],
      "metadata": {
        "id": "2-wfmHYVvmm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Add your layer\n",
        "\n",
        "Now we are going to write our own custom layer that is supposed to apply input feature scaling. For this, we subclass the `tf.keras.layers.Layer` base class and implement the minimal set of methods to integrate it into our model.\n",
        "\n"
      ],
      "metadata": {
        "id": "S7sNi6Wcn4L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the random data, which is a super position of gaussians\n",
        "data1 = np.random.normal(loc=3.0, scale=1.0, size=(100, 32))\n",
        "data2 = np.random.normal(loc=5.0, scale=2.0, size=(100, 32))\n",
        "\n",
        "composed_data = np.concatenate([data1, data2], axis=0)\n",
        "np.random.shuffle(composed_data)\n",
        "composed_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tJd7j0U2q0D",
        "outputId": "06fb6458-6f64-4d36-ff51-4ae5dd9e06ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.05504154, 2.79018988, 1.72821344, ..., 2.54600696, 4.04501132,\n",
              "        3.95596906],\n",
              "       [5.17977536, 5.06266596, 2.31131453, ..., 6.66998048, 1.63773041,\n",
              "        4.1835336 ],\n",
              "       [4.67971617, 4.5988274 , 3.92547357, ..., 6.64876942, 3.85227336,\n",
              "        6.71117932],\n",
              "       ...,\n",
              "       [2.31826299, 4.59579986, 5.17654838, ..., 3.04805325, 2.96284934,\n",
              "        2.6495997 ],\n",
              "       [3.63967808, 4.61357328, 9.30025715, ..., 2.49433114, 4.25265174,\n",
              "        6.50498244],\n",
              "       [5.63330117, 3.60716777, 6.27400824, ..., 3.23925531, 8.33567288,\n",
              "        6.0906125 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# meansure mean and standard deviation of the composed data\n",
        "# this is done across axis 0, i.e., measured per input feature across the batch axis\n",
        "means = np.mean(composed_data, axis=0)\n",
        "stddevs = np.std(composed_data, axis=0)"
      ],
      "metadata": {
        "id": "l2Q1wHHj6Eyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Input(shape=(32,))\n",
        "\n",
        "# add the feature scaling layer, passing the previously measured means and stddevs\n",
        "fs = FeatureScaling(means, stddevs)(x)\n",
        "\n",
        "# stack hidden layers\n",
        "a = fs\n",
        "for _ in range(5):\n",
        "    # dense layer\n",
        "    a = tf.keras.layers.Dense(128)(a)\n",
        "\n",
        "    # activation\n",
        "    a = tf.keras.layers.Activation(\"elu\")(a)\n",
        "\n",
        "# output layer\n",
        "y = tf.keras.layers.Dense(3, activation=\"softmax\")(a)\n",
        "\n",
        "# construct the model\n",
        "model = tf.keras.Model(inputs=x, outputs=y)"
      ],
      "metadata": {
        "id": "9ANf2HOr3zZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we can verify that our model actual predicts something 👾"
      ],
      "metadata": {
        "id": "JEhNUWhC45Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the batch we created and show the first ten predictions\n",
        "pred = model.predict(composed_data)\n",
        "pred[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDat8GMM5Bq1",
        "outputId": "f385744d-11e3-4f00-cab5-3eee1fe4526c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29628858, 0.3303082 , 0.37340322],\n",
              "       [0.39025533, 0.31435713, 0.29538757],\n",
              "       [0.29114312, 0.38839746, 0.3204594 ],\n",
              "       [0.3950846 , 0.23325928, 0.3716562 ],\n",
              "       [0.3094837 , 0.37747917, 0.31303716],\n",
              "       [0.44303316, 0.27193996, 0.2850269 ],\n",
              "       [0.298977  , 0.25975996, 0.44126314],\n",
              "       [0.1750406 , 0.51542217, 0.3095372 ],\n",
              "       [0.3190634 , 0.4872547 , 0.19368191],\n",
              "       [0.50432557, 0.21591039, 0.27976406]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice!"
      ],
      "metadata": {
        "id": "FQzP0Wuq69Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Extend your network\n",
        "\n",
        "The functional API is very flexible. In fact, you do not have to stick with a simple, single-purpose network but you can extend it to model a network with **multiple purposes**.\n",
        "\n",
        "Take your network from before, and change it to have the following architecture:\n",
        "\n",
        "#### Common network\n",
        "\n",
        "- 32 input features\n",
        "- 3 hidden layers with 128 units each\n",
        "- \"elu\" activation function\n",
        "\n",
        "#### Classification \"head\"\n",
        "\n",
        "- 3 hidden layers with 128 units each\n",
        "- \"elu\" activation function\n",
        "- a final \"softmax\" layer with 3 units (3-class classification)\n",
        "\n",
        "#### Regression \"head\"\n",
        "\n",
        "- 5 hidden layers with 64 units each\n",
        "- \"selu\" activation function\n",
        "- a final \"linear\" layer with a single units"
      ],
      "metadata": {
        "id": "1lG2IeJ37JuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Input(shape=(32,))\n",
        "\n",
        "# add the feature scaling layer, passing the previously measured means and stddevs\n",
        "fs = FeatureScaling(means, stddevs)(x)\n",
        "\n",
        "# common layers\n",
        "a = fs\n",
        "for _ in range(3):\n",
        "    # dense layer\n",
        "    a = tf.keras.layers.Dense(128)(a)\n",
        "\n",
        "    # activation\n",
        "    a = tf.keras.layers.Activation(\"elu\")(a)\n",
        "\n",
        "# classification head\n",
        "b = a\n",
        "for _ in range(3):\n",
        "    # dense layer\n",
        "    b = tf.keras.layers.Dense(128)(b)\n",
        "\n",
        "    # activation\n",
        "    b = tf.keras.layers.Activation(\"elu\")(b)\n",
        "\n",
        "# classification output\n",
        "y1 = tf.keras.layers.Dense(3, activation=\"softmax\")(b)\n",
        "\n",
        "# regression head\n",
        "c = a\n",
        "for _ in range(5):\n",
        "    # dense layer\n",
        "    c = tf.keras.layers.Dense(64)(c)\n",
        "\n",
        "    # activation\n",
        "    c = tf.keras.layers.Activation(\"selu\")(c)\n",
        "\n",
        "# regression output\n",
        "y2 = tf.keras.layers.Dense(1, activation=\"linear\")(c)\n",
        "\n",
        "# construct the model\n",
        "model = tf.keras.Model(inputs=x, outputs=[y1, y2])"
      ],
      "metadata": {
        "id": "AqUblMBs7231"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And again, run the model prediction, which now returns **2** outputs!"
      ],
      "metadata": {
        "id": "UOwpcZrR8ngF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the batch we created and show the first ten predictions\n",
        "class_pred, reg_pred = model.predict(composed_data)\n",
        "\n",
        "print(f\"first 10 class predictions:\\n{class_pred[:10]}\\n\")\n",
        "print(f\"first 10 regression predictions:\\n{reg_pred[:10]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYpc_XjJ8jus",
        "outputId": "868c3b6c-5b47-462b-f90e-c218a88d17bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first 10 class predictions:\n",
            "[[0.37955564 0.33074188 0.28970245]\n",
            " [0.3159389  0.28614768 0.39791343]\n",
            " [0.37199733 0.4678949  0.16010778]\n",
            " [0.3496212  0.40378    0.24659882]\n",
            " [0.27101213 0.504284   0.22470388]\n",
            " [0.36760885 0.34206164 0.29032958]\n",
            " [0.34607583 0.46843258 0.18549164]\n",
            " [0.22013687 0.59021086 0.18965226]\n",
            " [0.47388566 0.2144965  0.31161797]\n",
            " [0.2741796  0.17448226 0.55133814]]\n",
            "\n",
            "first 10 regression predictions:\n",
            "[[ 1.1370442 ]\n",
            " [-2.4196193 ]\n",
            " [-0.1467264 ]\n",
            " [-0.14404503]\n",
            " [ 1.5875952 ]\n",
            " [-2.3881588 ]\n",
            " [ 0.9758812 ]\n",
            " [ 0.9619354 ]\n",
            " [-1.7457979 ]\n",
            " [-0.16360575]]\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}